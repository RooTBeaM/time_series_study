{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : https://github.com/atulpatelDS/Youtube/blob/main/Feature_Engineering/Feature%20Selection%20using%20Correlation%20and%20Ranking%20Filter%20methods%20-Check%20Multi-collinearity-%20Tutorial%205.ipynb\n",
    "\n",
    "**Correlation & Ranking Filter Methods for Feature Selection or Check the Multicollinearity in Features**\n",
    "\n",
    "1. Low correlation means there's no linear relationship; it doesn't mean there's no information in the feature that predicts the target so in real life problem we don't delete those features which are not correlated with target.\n",
    "2. It might be a good idea to remove one of the highly correlated between themselves non-target features, because they might be redundant.\n",
    "3. In case of ordinals or binary features,as you can see columns('season','holiday', 'workingday', 'weather') correlation with Target won't tell you a lot. So I guess, the best way to test if a feature is important in case it's not correlated with target is to directly compare performance of a model with and without the feature. But still different features might have different importance for different algorithms.\n",
    "4. If a feature is strongly correlated with your label, this means a linear function (or model) should be able to predict well the latter. Even if it is not correlated, it doesn't tell you that a non-linear model wouldn't perform well by using this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def MAE(y_true,y_pred):\n",
    "    return round(mean_absolute_error(y_true,y_pred),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1059, 84), (400, 84))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 400\n",
    "target = 'y2'\n",
    "df_fulldata = pd.read_csv(\"./src/generated_data.csv\").drop(columns = ['trend_data','season_data','noise_data','actual','y','y1','actual_y1','actual_y2'])\n",
    "df_train = df_fulldata.loc[0:df_fulldata.shape[0]-num-1]\n",
    "df_test = df_fulldata.loc[df_fulldata.shape[0]-num:]\n",
    "\n",
    "X_train = df_train.drop(columns=target)\n",
    "y_train = df_train[target]\n",
    "X_test = df_test.drop(columns=target)\n",
    "y_test = df_test[target]\n",
    "\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=0.95)\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "X_mm_train = mm.fit_transform(X_train)\n",
    "X_mm_test = mm.transform(X_test)\n",
    "\n",
    "y_mm_train = mm.fit_transform(y_train.to_numpy().reshape(-1,1))\n",
    "y_mm_test = mm.transform(y_test.to_numpy().reshape(-1,1))\n",
    "\n",
    "X_pca_train = pca.fit_transform(scaler.fit_transform(X_train))\n",
    "X_pca_test = pca.transform(scaler.transform(X_test))\n",
    "\n",
    "df_pca_train = pd.DataFrame(X_pca_train)\n",
    "df_pca_test = pd.DataFrame(X_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.877497\n",
      "MAE train : 8.41\n",
      "R^2: 0.479804\n",
      "MAE test : 8.77\n"
     ]
    }
   ],
   "source": [
    "base_model = LinearRegression().fit(X_train, y_train)\n",
    "# Returning the R^2 for the model\n",
    "base_model_r2 = base_model.score(X_train, y_train)\n",
    "y_pred = base_model.predict(X_train)\n",
    "print(f'R^2: {base_model_r2:4f}')\n",
    "print(f\"MAE train : {MAE(y_pred, y_train)}\")\n",
    "\n",
    "base_model_r2 = base_model.score(X_test, y_test)\n",
    "y_pred = base_model.predict(X_test)\n",
    "print(f'R^2: {base_model_r2:4f}')\n",
    "print(f\"MAE test : {MAE(y_pred, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "- Pearson’s correlation coefficient(linear data)\n",
    "- Spearman’s rank coefficient(linear and nonlinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to calculate correlation between all features and remove highly correlated ones\n",
    "def correlation(df, threshold=0.8, method='spearman'):\n",
    "    dataset = df.copy()\n",
    "    col_corr = list() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr(method=method)\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.append(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname] # deleting the column from the dataset\n",
    "    print(f\"Final X shape : {dataset.shape}\")\n",
    "    return dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X shape : (1059, 25)\n"
     ]
    }
   ],
   "source": [
    "feature_ls = correlation(X_train,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.873993\n",
      "MAE train : 8.6\n",
      "R^2: 0.478898\n",
      "MAE test : 8.81\n"
     ]
    }
   ],
   "source": [
    "corr_model = LinearRegression().fit(X_train[feature_ls], y_train)\n",
    "# Returning the R^2 for the model\n",
    "corr_model_r2 = corr_model.score(X_train[feature_ls], y_train)\n",
    "y_pred = corr_model.predict(X_train[feature_ls])\n",
    "print(f'R^2: {corr_model_r2:4f}')\n",
    "print(f\"MAE train : {MAE(y_pred, y_train)}\")\n",
    "\n",
    "corr_model_r2 = corr_model.score(X_test[feature_ls], y_test)\n",
    "y_pred = corr_model.predict(X_test[feature_ls])\n",
    "print(f'R^2: {corr_model_r2:4f}')\n",
    "print(f\"MAE test : {MAE(y_pred, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corr by Demand project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
